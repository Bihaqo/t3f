{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "quick_start.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAdpYMvhjExj",
        "colab_type": "text"
      },
      "source": [
        "# Quick start\n",
        "\n",
        "[Open](https://colab.research.google.com/github/Bihaqo/t3f/blob/develop/docs/quick_start.ipynb) **this page in an interactive mode via Google Colaboratory.**\n",
        "\n",
        "In this quick starting guide we show the basics of working with t3f library. The main concept of the library is a TensorTrain object -- a compact (factorized) representation of a tensor (=multidimensional array). This is generalization of the matrix low-rank decomposition.\n",
        "\n",
        "\n",
        "To begin, let's import some libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oUv_JuSjExl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12d6ddbb-019c-44af-9b0a-4efc74b81948"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Import TF 2.\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Fix seed so that the results are reproducable.\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "try:\n",
        "    import t3f\n",
        "except ImportError:\n",
        "    # Install T3F if it's not already installed.\n",
        "    !git clone https://github.com/Bihaqo/t3f.git\n",
        "    !cd t3f; pip install .\n",
        "    import t3f"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUSpAcUNjExo",
        "colab_type": "text"
      },
      "source": [
        "Converting to and from TT-format\n",
        "------------------------------------------------\n",
        "\n",
        "Let's start with converting a dense (numpy) matrix into the TT-format, which in this case coincides with the low-rank format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maLG_cgGjExp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "50136303-f57b-4f42-c4d0-c90bb0e46ee5"
      },
      "source": [
        "# Generate a random dense matrix of size 3 x 4.\n",
        "a_dense = np.random.randn(3, 4)\n",
        "# Convert the matrix into the TT-format with TT-rank = 3 (the larger the TT-rank,\n",
        "# the more exactly the tensor will be converted, but the more memory and time\n",
        "# everything will take). For matrices, matrix rank coinsides with TT-rank.\n",
        "a_tt = t3f.to_tt_tensor(a_dense, max_tt_rank=3)\n",
        "# a_tt stores the factorized representation of the matrix, namely it stores the matrix\n",
        "# as a product of two smaller matrices which are called TT-cores. You can\n",
        "# access the TT-cores directly.\n",
        "print('factors of the matrix: ', a_tt.tt_cores)\n",
        "# To check that the convertions into the TT-format didn't change the matrix too much,\n",
        "# let's convert it back and compare to the original.\n",
        "reconstructed_matrix = t3f.full(a_tt)\n",
        "print('Original matrix: ')\n",
        "print(a_dense)\n",
        "print('Reconstructed matrix: ')\n",
        "print(reconstructed_matrix)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "factors of the matrix:  (<tf.Tensor: shape=(1, 3, 3), dtype=float64, numpy=\n",
            "array([[[-0.86358906, -0.23239721,  0.44744327],\n",
            "        [-0.42523249,  0.81253763, -0.3986978 ],\n",
            "        [-0.27090823, -0.53457847, -0.80052145]]])>, <tf.Tensor: shape=(3, 4, 1), dtype=float64, numpy=\n",
            "array([[[-2.2895998 ],\n",
            "        [-0.04123559],\n",
            "        [-1.28825847],\n",
            "        [-2.2648235 ]],\n",
            "\n",
            "       [[ 1.16267886],\n",
            "        [-1.10656759],\n",
            "        [ 0.46752401],\n",
            "        [-1.42118407]],\n",
            "\n",
            "       [[ 0.12735099],\n",
            "        [ 0.23999328],\n",
            "        [-0.05617841],\n",
            "        [-0.10115877]]])>)\n",
            "Original matrix: \n",
            "[[ 1.76405235  0.40015721  0.97873798  2.2408932 ]\n",
            " [ 1.86755799 -0.97727788  0.95008842 -0.15135721]\n",
            " [-0.10321885  0.4105985   0.14404357  1.45427351]]\n",
            "Reconstructed matrix: \n",
            "tf.Tensor(\n",
            "[[ 1.76405235  0.40015721  0.97873798  2.2408932 ]\n",
            " [ 1.86755799 -0.97727788  0.95008842 -0.15135721]\n",
            " [-0.10321885  0.4105985   0.14404357  1.45427351]], shape=(3, 4), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZTU_7r3jExu",
        "colab_type": "text"
      },
      "source": [
        "The same idea applies to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt9bqmSsjExv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cace78a7-84e9-4d3d-ff0e-b664d5b10dde"
      },
      "source": [
        "# Generate a random dense tensor of size 3 x 2 x 2.\n",
        "a_dense = np.random.randn(3, 2, 2).astype(np.float32)\n",
        "# Convert the tensor into the TT-format with TT-rank = 3.\n",
        "a_tt = t3f.to_tt_tensor(a_dense, max_tt_rank=3)\n",
        "# The 3 TT-cores are available in a_tt.tt_cores.\n",
        "# To check that the convertions into the TT-format didn't change the tensor too much,\n",
        "# let's convert it back and compare to the original.\n",
        "reconstructed_tensor = t3f.full(a_tt)\n",
        "print('The difference between the original tensor and the reconsrtucted '\n",
        "      'one is %f' % np.linalg.norm(reconstructed_tensor - a_dense))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The difference between the original tensor and the reconsrtucted one is 0.000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKLybqtAjEx1",
        "colab_type": "text"
      },
      "source": [
        "Arithmetic operations\n",
        "--------------------------------\n",
        "\n",
        "T3F is a library of different operations that can be applied to the tensors in the TT-format by working directly with the compact representation, i.e. without the need to materialize the tensors themself.\n",
        "Here are some basic examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDdvofu8jEx2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e4bc7e61-1d99-494f-bc8b-258e540ed1ec"
      },
      "source": [
        "# Create a random tensor of shape (3, 2, 2) directly in the TT-format\n",
        "# (in contrast to generating a dense tensor and then converting it to TT).\n",
        "b_tt = t3f.random_tensor((3, 2, 2), tt_rank=2)\n",
        "# Compute the Frobenius norm of the tensor.\n",
        "norm = t3f.frobenius_norm(b_tt)\n",
        "print('Frobenius norm of the tensor is %f' % norm)\n",
        "# Compute the TT-representation of the sum or elementwise product of two TT-tensors.\n",
        "sum_tt = a_tt + b_tt\n",
        "prod_tt = a_tt * b_tt\n",
        "twice_a_tt = 2 * a_tt\n",
        "# Most operations on TT-tensors increase the TT-rank. After applying a sequence of\n",
        "# operations the TT-rank can increase by too much and we may want to reduce it.\n",
        "# To do that there is a rounding operation, which finds the tensor that is of\n",
        "# a smaller rank but is as close to the original one as possible.\n",
        "rounded_prod_tt = t3f.round(prod_tt, max_tt_rank=3)\n",
        "a_max_tt_rank = np.max(a_tt.get_tt_ranks())\n",
        "b_max_tt_rank = np.max(b_tt.get_tt_ranks())\n",
        "exact_prod_max_tt_rank = np.max(prod_tt.get_tt_ranks())\n",
        "rounded_prod_max_tt_rank = np.max(rounded_prod_tt.get_tt_ranks())\n",
        "difference = t3f.frobenius_norm(prod_tt - rounded_prod_tt)\n",
        "print('The TT-ranks of a and b are %d and %d. The TT-rank '\n",
        "      'of their elementwise product is %d. The TT-rank of '\n",
        "      'their product after rounding is %d. The difference '\n",
        "      'between the exact and the rounded elementwise '\n",
        "      'product is %f.' % (a_max_tt_rank, b_max_tt_rank,\n",
        "                         exact_prod_max_tt_rank,\n",
        "                         rounded_prod_max_tt_rank,\n",
        "                         difference))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frobenius norm of the tensor is 2.943432\n",
            "The TT-ranks of a and b are 3 and 2. The TT-rank of their elementwise product is 6. The TT-rank of their product after rounding is 3. The difference between the exact and the rounded elementwise product is 0.003162.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2beGpQP8jEx5",
        "colab_type": "text"
      },
      "source": [
        "Working with TT-matrices\n",
        "------------------------------------\n",
        "\n",
        "Recall that for 2-dimensional tensors the TT-format coincides with the matrix low-rank format. However, sometimes matrices can have full matrix rank, but some tensor structure (for example a kronecker product of matrices). In this case there is a special object called Matrix TT-format. You can think of it as a sum of kronecker products (although it's a bit more complicated than that).\n",
        "\n",
        "Let's say that you have a matrix of size 8 x 27. You can convert it into the matrix TT-format of tensor shape (2, 2, 2) x (3, 3, 3) (in which case the matrix will be represented with 3 TT-cores) or, for example, into the matrix TT-format of tensor shape (4, 2) x (3, 9) (in which case the matrix will be represented with 2 TT-cores)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsYbLqLPjEx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ee19827-50d2-4826-b5f6-1a321425a47b"
      },
      "source": [
        "a_dense = np.random.rand(8, 27).astype(np.float32)\n",
        "a_matrix_tt = t3f.to_tt_matrix(a_dense, shape=((2, 2, 2), (3, 3, 3)), max_tt_rank=4)\n",
        "# Now you can work with 'a_matrix_tt' like with any other TT-object, e.g.\n",
        "print('Frobenius norm of the matrix is %f' % t3f.frobenius_norm(a_matrix_tt))\n",
        "twice_a_matrix_tt = 2.0 * a_matrix_tt  # multiplication by a number.\n",
        "prod_tt = a_matrix_tt * a_matrix_tt  # Elementwise product of two TT-matrices.\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frobenius norm of the matrix is 7.805310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZubUrinMjEx9",
        "colab_type": "text"
      },
      "source": [
        "But, additionally, you can also compute matrix multiplication between TT-matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNVmZAe6jEx-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0e80ee65-0041-4384-a240-fd5091ae59e3"
      },
      "source": [
        "vector_tt = t3f.random_matrix(((3, 3, 3), (1, 1, 1)), tt_rank=3)\n",
        "matvec_tt = t3f.matmul(a_matrix_tt, vector_tt)\n",
        "# Check that the result coinsides with np.matmul.\n",
        "matvec_expected = np.matmul(t3f.full(a_matrix_tt), t3f.full(vector_tt))\n",
        "difference = np.linalg.norm(matvec_expected - t3f.full(matvec_tt))\n",
        "print('Difference between multiplying matrix by vector in '\n",
        "      'the TT-format and then converting the result into '\n",
        "      'dense vector and multiplying dense matrix by '\n",
        "      'dense vector is %f.' % difference)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Difference between multiplying matrix by vector in the TT-format and then converting the result into dense vector and multiplying dense matrix by dense vector is 0.000001.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}