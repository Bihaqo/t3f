{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensor_nets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PbT4UV21L9p",
        "colab_type": "text"
      },
      "source": [
        "# Tensor Nets (compressing neural networks)\n",
        "\n",
        "[Open](https://colab.research.google.com/github/Bihaqo/t3f/blob/develop/docs/tutorials/tensor_nets.ipynb) **this page in an interactive mode via Google Colaboratory.**\n",
        "\n",
        "In this notebook we provide an example of how to build a simple Tensor Net (see https://arxiv.org/abs/1509.06569).\n",
        "\n",
        "The main ingredient is the so-called TT-Matrix, a generalization of the Kronecker product matrices, i.e. matrices of the form \n",
        "$$A = A_1 \\otimes A_2 \\cdots \\otimes A_n$$\n",
        "\n",
        "In `t3f` TT-Matrices are represented using the `TensorTrain` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zf7mDAV1L9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "a94b9f97-6875-4e92-ed0a-3adffb7875e4"
      },
      "source": [
        "# Import TF 2.\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Fix seed so that the results are reproducable.\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "try:\n",
        "    import t3f\n",
        "except ImportError:\n",
        "    # Install T3F if it's not already installed.\n",
        "    !git clone https://github.com/Bihaqo/t3f.git\n",
        "    !cd t3f; pip install .\n",
        "    import t3f"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Cloning into 't3f'...\n",
            "remote: Enumerating objects: 321, done.\u001b[K\n",
            "remote: Counting objects: 100% (321/321), done.\u001b[K\n",
            "remote: Compressing objects: 100% (182/182), done.\u001b[K\n",
            "remote: Total 4715 (delta 209), reused 226 (delta 139), pack-reused 4394\u001b[K\n",
            "Receiving objects: 100% (4715/4715), 1.52 MiB | 1.26 MiB/s, done.\n",
            "Resolving deltas: 100% (3203/3203), done.\n",
            "Processing /content/t3f\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from t3f==1.1.0) (1.18.1)\n",
            "Building wheels for collected packages: t3f\n",
            "  Building wheel for t3f (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for t3f: filename=t3f-1.1.0-cp36-none-any.whl size=75051 sha256=a20c22745abcbe82d9a467cf607135da9d5399940712bfbf134bbf7e40ac53b3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vnw71g5i/wheels/66/f2/16/8d2b16c34f7e12d446db3584514f9e34e681f4c602325d175c\n",
            "Successfully built t3f\n",
            "Installing collected packages: t3f\n",
            "Successfully installed t3f-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTArGyPc1L9w",
        "colab_type": "code",
        "outputId": "0debe6f0-689c-4dbd-dc87-26831f1b539d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "W = t3f.random_matrix([[4, 7, 4, 7], [5, 5, 5, 5]], tt_rank=2)\n",
        "\n",
        "print(W)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A TT-Matrix of size 784 x 625, underlying tensor shape: (4, 7, 4, 7) x (5, 5, 5, 5), TT-ranks: (1, 2, 2, 2, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQOaaA4R1L91",
        "colab_type": "text"
      },
      "source": [
        "Using TT-Matrices we can compactly represent densely connected layers in neural networks, which allows us to greatly reduce number of parameters. Matrix multiplication can be handled by the `t3f.matmul` method which allows for multiplying dense (ordinary) matrices and TT-Matrices. Very simple neural network could look as following (for initialization several options such as `t3f.glorot_initializer`, `t3f.he_initializer` or `t3f.random_matrix` are available):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLvV49Cd1L93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Learner:\n",
        "  def __init__(self):\n",
        "    initializer = t3f.glorot_initializer([[4, 7, 4, 7], [5, 5, 5, 5]], tt_rank=2)\n",
        "    self.W1 = t3f.get_variable('W1', initializer=initializer)\n",
        "    self.W2 = tf.Variable(tf.random.normal([625, 10]))\n",
        "    self.b2 = tf.Variable(tf.random.normal([10]))\n",
        "  \n",
        "  def predict(self, x):\n",
        "    b1 = tf.Variable(tf.zeros([625]))\n",
        "    h1 = t3f.matmul(x, W1) + b1\n",
        "    h1 = tf.nn.relu(h1)\n",
        "    return tf.matmul(h1, W2) + b2\n",
        "\n",
        "  def loss(self, x, y):\n",
        "    y_ = tf.one_hot(y, 10)\n",
        "    logits = self.predict(x)\n",
        "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZCtiSnC1L94",
        "colab_type": "text"
      },
      "source": [
        "For convenience we have implemented a layer analogous to *Keras* `Dense` layer but with a TT-Matrix instead of an ordinary matrix. An example of fully trainable net is provided below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ9KEc201L95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVLgpYF_1L99",
        "colab_type": "code",
        "outputId": "ef5cfb9b-ca2b-4ddd-c298-3e050a4f7cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "astcob7O1L9-",
        "colab_type": "text"
      },
      "source": [
        "Some preprocessing..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoBbdpGP1L9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train / 127.5 - 1.0\n",
        "x_test = x_test / 127.5 - 1.0\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEa9GBp81L-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "tt_layer = t3f.nn.KerasDense(input_dims=[7, 4, 7, 4], output_dims=[5, 5, 5, 5],\n",
        "                             tt_rank=4, activation='relu',\n",
        "                             bias_initializer=1e-3)\n",
        "model.add(tt_layer)\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MApNz_T31L-G",
        "colab_type": "code",
        "outputId": "d072588c-9a29-40fc-cd24-9205520f6c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_12 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "tt_dense_1 (KerasDense)      (None, 625)               1725      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                6260      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 7,985\n",
            "Trainable params: 7,985\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4zrSP531L-K",
        "colab_type": "text"
      },
      "source": [
        "Note that in the dense layer we only have $1725$ parameters instead of $784 * 625 = 490000$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyqaT09O1L-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optimizers.Adam(lr=1e-2)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF9NrphG1L-O",
        "colab_type": "code",
        "outputId": "e95b6dd6-7ca5-4ba4-ab92-0ee9d73562a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=3, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2549 - accuracy: 0.9248 - val_loss: 0.1195 - val_accuracy: 0.9638\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1448 - accuracy: 0.9574 - val_loss: 0.1415 - val_accuracy: 0.9585\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1308 - accuracy: 0.9619 - val_loss: 0.1198 - val_accuracy: 0.9638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd5263629b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "J9IVspp61L-R",
        "colab_type": "text"
      },
      "source": [
        "Compression of Dense layers\n",
        "------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "mIl7XppU1L-S",
        "colab_type": "text"
      },
      "source": [
        "Let us now train an ordinary DNN (without TT-Matrices) and show how we can compress it using the TT decomposition. (In contrast to directly training a TT-layer from scratch in the example above.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnWQ5MCk1L-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(625, activation='relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBS-c6YK1L-V",
        "colab_type": "code",
        "outputId": "452e2405-95bf-42b5-d20f-abc0a3717823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_13 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 625)               490625    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                6260      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 496,885\n",
            "Trainable params: 496,885\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdJIVj5W1L-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optimizers.Adam(lr=1e-3)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdv8q1S61L-a",
        "colab_type": "code",
        "outputId": "1190dad9-2d43-41f9-a6aa-1defbfcb3e8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.2779 - accuracy: 0.9158 - val_loss: 0.1589 - val_accuracy: 0.9501\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 3s 52us/sample - loss: 0.1297 - accuracy: 0.9610 - val_loss: 0.1632 - val_accuracy: 0.9483\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0991 - accuracy: 0.9692 - val_loss: 0.1083 - val_accuracy: 0.9674\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0835 - accuracy: 0.9742 - val_loss: 0.1191 - val_accuracy: 0.9619\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0720 - accuracy: 0.9771 - val_loss: 0.0918 - val_accuracy: 0.9714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd5260c8240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdLn-FIK1L-g",
        "colab_type": "text"
      },
      "source": [
        "Let us convert the matrix used in the Dense layer to the TT-Matrix with tt-ranks equal to 16 (since we trained the network without the low-rank structure assumption we may wish start with high rank values)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBqfSwZf1L-g",
        "colab_type": "code",
        "outputId": "ff7f8d86-7210-4549-abf7-df0ba50d2fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "W = model.trainable_weights[0]\n",
        "print(W)\n",
        "Wtt = t3f.to_tt_matrix(W, shape=[[7, 4, 7, 4], [5, 5, 5, 5]], max_tt_rank=16)\n",
        "print(Wtt)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'dense_9/kernel:0' shape=(784, 625) dtype=float32, numpy=\n",
            "array([[-0.03238887,  0.06103956,  0.03255948, ..., -0.02577683,\n",
            "         0.06993102, -0.00263362],\n",
            "       [-0.05367032, -0.0324776 , -0.04441883, ...,  0.0338573 ,\n",
            "         0.01554517,  0.04145934],\n",
            "       [ 0.03441307,  0.04183276,  0.05157001, ...,  0.00082603,\n",
            "         0.03731582, -0.01392014],\n",
            "       ...,\n",
            "       [ 0.03070629,  0.02113252,  0.01526976, ..., -0.00541451,\n",
            "         0.03794012,  0.04027091],\n",
            "       [-0.01376432, -0.0064889 , -0.03118961, ...,  0.06237663,\n",
            "        -0.000577  , -0.02628548],\n",
            "       [-0.01680673,  0.00364697,  0.01722438, ...,  0.01579029,\n",
            "        -0.00826585,  0.03203061]], dtype=float32)>\n",
            "A TT-Matrix of size 784 x 625, underlying tensor shape: (7, 4, 7, 4) x (5, 5, 5, 5), TT-ranks: (1, 16, 16, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIbCDkyA1L-i",
        "colab_type": "text"
      },
      "source": [
        "We need to evaluate the tt-cores of Wtt. We also need to store other parameters for later (biases and the second dense layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tscSHv7X1L-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cores = Wtt.tt_cores\n",
        "other_params = model.get_weights()[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llryIpkW1L-l",
        "colab_type": "text"
      },
      "source": [
        "Now we can construct a tensor network with the first Dense layer replaced by `Wtt`\n",
        "initialized using the previously computed cores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8zQfyNu1L-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "tt_layer = t3f.nn.KerasDense(input_dims=[7, 4, 7, 4], output_dims=[5, 5, 5, 5],\n",
        "                             tt_rank=16, activation='relu')\n",
        "model.add(tt_layer)\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_BGc2MV1L-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optimizers.Adam(lr=1e-3)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BllmgHlt1L-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.set_weights(list(cores) + other_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwB7UfTV1L-x",
        "colab_type": "code",
        "outputId": "d8520308-bf5d-4503-d60a-be2eea0c13ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"new accuracy: \", model.evaluate(x_test, y_test)[1])"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 91us/sample - loss: 1.0276 - accuracy: 0.6443\n",
            "new accuracy:  0.6443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnnru3s51L-0",
        "colab_type": "code",
        "outputId": "0e8a24c1-be50-403f-aa67-e427931570a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_16 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "tt_dense_2 (KerasDense)      (None, 625)               15585     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                6260      \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 21,845\n",
            "Trainable params: 21,845\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cba_5ExM1L-5",
        "colab_type": "text"
      },
      "source": [
        "We see that even though we now have about 5% of the original number of parameters we still achieve a relatively high accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFCEZjP11L-5",
        "colab_type": "text"
      },
      "source": [
        "Finetuning the model \n",
        "-------------------------------\n",
        "We can now finetune this tensor network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "268p2zec1L-6",
        "colab_type": "code",
        "outputId": "a3022433-e217-48cc-e8c3-16479372a737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=2, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1349 - accuracy: 0.9594 - val_loss: 0.0982 - val_accuracy: 0.9703\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.0822 - accuracy: 0.9750 - val_loss: 0.0826 - val_accuracy: 0.9765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd526574198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX2XYk4J1L_A",
        "colab_type": "text"
      },
      "source": [
        "We see that we were able to achieve higher validation accuracy than we had in the plain DNN, while keeping the number of parameters extremely small (21845 vs 496885 parameters in the uncompressed model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w81lLRov1L_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}